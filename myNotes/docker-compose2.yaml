version: '3.8'

services:
  text-generation:
    image: ghcr.io/huggingface/text-generation-inference
    shm_size: '10g'
    ports:
      - '8080:80'
    environment:
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
    command:
      - "--model-id"
      - "meta-llama/Llama-3.2-1B"         
      - "--dtype"
      - "float16"                          
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ['gpu']
